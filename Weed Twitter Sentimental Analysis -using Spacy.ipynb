{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import math\n",
    "\n",
    "\n",
    "#Function to convert data into lowercase\n",
    "def convert_lower_case(data):\n",
    "    return np.char.lower(data)\n",
    "\n",
    "\n",
    "#function to remove stopwords using nltk corpus\n",
    "def remove_stop_words(data):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return new_text\n",
    "\n",
    "\n",
    "#This function removes special character/puntuations with space\n",
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data\n",
    "\n",
    "\n",
    "#This function removes apostrophe\n",
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")\n",
    "\n",
    "\n",
    "#This function uses PorterStemmer for stemming ie to find the root form of the words\n",
    "def stemming(data):\n",
    "    stemmer= PorterStemmer()\n",
    "    \n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        new_text = new_text + \" \" + stemmer.stem(w)\n",
    "    return new_text\n",
    "\n",
    "\n",
    "#num2words is a library that converts numbers like 42 to words like forty-two.\n",
    "def convert_numbers(data):\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text\n",
    "\n",
    "\n",
    "#This is a preprocessing pipeline which calls all the functions together for cleaning the data.\n",
    "def preprocess(data):\n",
    "    data = convert_lower_case(data)\n",
    "    data = remove_punctuation(data) #remove comma seperately\n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_stop_words(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = stemming(data)\n",
    "    data = remove_punctuation(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = stemming(data) #needed again as we need to stem the words\n",
    "    data = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\n",
    "    data = remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading CSV file\n",
    "df_weed = pd.read_csv (\"weed_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00 Seeds</td>\n",
       "      <td>Cultivation</td>\n",
       "      <td>White Widow</td>\n",
       "      <td>Selección de White Widow, planta compacta de g...</td>\n",
       "      <td>legitplug001</td>\n",
       "      <td>Positive</td>\n",
       "      <td>CALL OR TEXT...310.912.31.45 Got Buds/Edibles/...</td>\n",
       "      <td>No Retailers Found Near You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00 Seeds</td>\n",
       "      <td>Cultivation</td>\n",
       "      <td>White Widow</td>\n",
       "      <td>Selección de White Widow, planta compacta de g...</td>\n",
       "      <td>Manue3</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I have medical cannabis for sale 0z 250, 1/8lb...</td>\n",
       "      <td>No Retailers Found Near You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00 Seeds</td>\n",
       "      <td>Cultivation</td>\n",
       "      <td>White Widow</td>\n",
       "      <td>Selección de White Widow, planta compacta de g...</td>\n",
       "      <td>autreykenneth</td>\n",
       "      <td>Positive</td>\n",
       "      <td>one of the best strains ihave ever tried</td>\n",
       "      <td>No Retailers Found Near You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00 Seeds</td>\n",
       "      <td>Cultivation</td>\n",
       "      <td>White Widow</td>\n",
       "      <td>Selección de White Widow, planta compacta de g...</td>\n",
       "      <td>RasRojas</td>\n",
       "      <td>Positive</td>\n",
       "      <td>como compro weeed</td>\n",
       "      <td>No Retailers Found Near You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00 Seeds</td>\n",
       "      <td>Cultivation</td>\n",
       "      <td>White Widow</td>\n",
       "      <td>Selección de White Widow, planta compacta de g...</td>\n",
       "      <td>Kathyd47</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Need. Intact info for online or phone call in ...</td>\n",
       "      <td>No Retailers Found Near You</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand      Product Product Name  \\\n",
       "0  00 Seeds  Cultivation  White Widow   \n",
       "1  00 Seeds  Cultivation  White Widow   \n",
       "2  00 Seeds  Cultivation  White Widow   \n",
       "3  00 Seeds  Cultivation  White Widow   \n",
       "4  00 Seeds  Cultivation  White Widow   \n",
       "\n",
       "                                 Product Description  Customer Name    Rating  \\\n",
       "0  Selección de White Widow, planta compacta de g...   legitplug001  Positive   \n",
       "1  Selección de White Widow, planta compacta de g...         Manue3  Positive   \n",
       "2  Selección de White Widow, planta compacta de g...  autreykenneth  Positive   \n",
       "3  Selección de White Widow, planta compacta de g...       RasRojas  Positive   \n",
       "4  Selección de White Widow, planta compacta de g...       Kathyd47  Positive   \n",
       "\n",
       "                                              Review  \\\n",
       "0  CALL OR TEXT...310.912.31.45 Got Buds/Edibles/...   \n",
       "1  I have medical cannabis for sale 0z 250, 1/8lb...   \n",
       "2           one of the best strains ihave ever tried   \n",
       "3                                  como compro weeed   \n",
       "4  Need. Intact info for online or phone call in ...   \n",
       "\n",
       "                     Locations  \n",
       "0  No Retailers Found Near You  \n",
       "1  No Retailers Found Near You  \n",
       "2  No Retailers Found Near You  \n",
       "3  No Retailers Found Near You  \n",
       "4  No Retailers Found Near You  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 records\n",
    "df_weed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20690, 8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of dataframe\n",
    "df_weed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20690 entries, 0 to 20689\n",
      "Data columns (total 8 columns):\n",
      "Brand                  20690 non-null object\n",
      "Product                20690 non-null object\n",
      "Product Name           20690 non-null object\n",
      "Product Description    20690 non-null object\n",
      "Customer Name          20690 non-null object\n",
      "Rating                 20690 non-null object\n",
      "Review                 20129 non-null object\n",
      "Locations              20690 non-null object\n",
      "dtypes: object(8)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# View data information\n",
    "df_weed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    18307\n",
       "Negative     1697\n",
       "Neutral       686\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feedback Value count\n",
    "df_weed.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "ylabels = df_weed['Rating'] # the labels, or answers, we want to test against\n",
    "\n",
    "preprocessed_text= []\n",
    "    \n",
    "for i in range(len(df_weed)):\n",
    "    \n",
    "    preprocessed_text.append(str(preprocess(str(df_weed.loc[i, \"Review\"]))))\n",
    "    \n",
    "X = pd.DataFrame(preprocessed_text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[0], ylabels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        CALL OR TEXT...310.912.31.45 Got Buds/Edibles/...\n",
       "1        I have medical cannabis for sale 0z 250, 1/8lb...\n",
       "2                 one of the best strains ihave ever tried\n",
       "3                                        como compro weeed\n",
       "4        Need. Intact info for online or phone call in ...\n",
       "                               ...                        \n",
       "20685    Not too strong or weak, great flavor combinati...\n",
       "20686    Nice gooey and chewy brownies. Tasted great. A...\n",
       "20687    Birthday Cake: 1600 Ice Cream Cake: 1700 Grape...\n",
       "20688                               Works well and lasts !\n",
       "20689    Buy medical cannabis, wax, shatter, rick simps...\n",
       "Name: Review, Length: 20690, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import pickle\n",
    "\n",
    "count_vect = CountVectorizer(tokenizer = spacy_tokenizer)\n",
    "X_train_counts = count_vect.fit_transform(X_train.values.astype('U'))\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "print(clf.predict(count_vect.transform([\"This I dont like this product it is bad\"])))\n",
    "y_pred=clf.predict(count_vect.transform(X_test.values.astype('U')))\n",
    "pickle.dump(clf, open('modelclfsvm.pkl','wb'))\n",
    "pickle.dump(count_vect, open('count_vect_svm', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----CONFUSTION MATRIX-----\n",
      "[[ 351   47   96]\n",
      " [  57   63   81]\n",
      " [ 337  275 4900]]\n",
      "-----CLASSIFICATION REPORT-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.47      0.71      0.57       494\n",
      "     Neutral       0.16      0.31      0.22       201\n",
      "    Positive       0.97      0.89      0.93      5512\n",
      "\n",
      "    accuracy                           0.86      6207\n",
      "   macro avg       0.53      0.64      0.57      6207\n",
      "weighted avg       0.90      0.86      0.87      6207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"-----CONFUSTION MATRIX-----\")\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"-----CLASSIFICATION REPORT-----\")\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading CSV file\n",
    "df_twitter = pd.read_csv (\"sentiment3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "ytlabels = df_twitter['Sentiment'] # the labels, or answers, we want to test against\n",
    "\n",
    "preprocessed_text= []\n",
    "    \n",
    "for i in range(len(df_twitter)):\n",
    "    \n",
    "    preprocessed_text.append(str(preprocess(str(df_twitter.loc[i, \"Tweet\"]))))\n",
    "    \n",
    "Xt = pd.DataFrame(preprocessed_text)\n",
    "\n",
    "Xt_train, Xt_test, yt_train, yt_test = train_test_split(Xt[0], ytlabels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(tokenizer = spacy_tokenizer)\n",
    "X_train_counts = count_vect.fit_transform(Xt_train.values.astype('U'))\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = model.fit(X_train_tfidf, yt_train)\n",
    "\n",
    "\n",
    "print(clf.predict(count_vect.transform([\"This I like this weed\"])))\n",
    "y_pred=clf.predict(count_vect.transform(Xt_test.values.astype('U')))\n",
    "pickle.dump(clf, open('modelclfsvm.pkl','wb'))\n",
    "pickle.dump(count_vect, open('count_vect_svm', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----CONFUSTION MATRIX-----\n",
      "[[  7  14   1]\n",
      " [  1 160   1]\n",
      " [  0  70  46]]\n",
      "-----CLASSIFICATION REPORT-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.32      0.47        22\n",
      "     neutral       0.66      0.99      0.79       162\n",
      "    positive       0.96      0.40      0.56       116\n",
      "\n",
      "    accuracy                           0.71       300\n",
      "   macro avg       0.83      0.57      0.61       300\n",
      "weighted avg       0.79      0.71      0.68       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"-----CONFUSTION MATRIX-----\")\n",
    "\n",
    "print(confusion_matrix(yt_test, y_pred))\n",
    "\n",
    "print(\"-----CLASSIFICATION REPORT-----\")\n",
    "\n",
    "print(classification_report(yt_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
